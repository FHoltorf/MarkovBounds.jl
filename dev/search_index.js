var documenterSearchIndex = {"docs":
[{"location":"functionalities/","page":"Functionalities","title":"Functionalities","text":"CurrentModule = MarkovBounds","category":"page"},{"location":"functionalities/#Functionalities-of-MarkovBounds.jl","page":"Functionalities","title":"Functionalities of MarkovBounds.jl","text":"","category":"section"},{"location":"functionalities/#Problem-Specification","page":"Functionalities","title":"Problem Specification","text":"","category":"section"},{"location":"functionalities/","page":"Functionalities","title":"Functionalities","text":"MarkovProcess\nJumpProcess\nReactionProcess\nDiffusionProcess\nJumpDiffusionProcess\nControlProcess\nLagrangeMayer\nTerminalSetProbability\nExitProbability","category":"page"},{"location":"functionalities/#MarkovBounds.MarkovProcess","page":"Functionalities","title":"MarkovBounds.MarkovProcess","text":"MarkovProcess\n\nAn abstract type to define stochastic processes that are supported by MarkovBounds.jl. \n\n\n\n\n\n","category":"type"},{"location":"functionalities/#MarkovBounds.JumpProcess","page":"Functionalities","title":"MarkovBounds.JumpProcess","text":"JumpProcess(x, a, h, X = FullSpace();\n            iv = PV{true}(\"t\"), controls = [], poly_vars = Dict())\n\nconstructor returns JumpProcess object with fields\n\nx - vector containing the system state. Can be specified both as PolyVar type object       from DynamicPolynomials.jl or Num type object generated by Catalyst.jl/ModelingToolkit.jl.        In the latter case, PolyVar variables with analogous names are generated automatically and       a dictionary is assembled that keeps track of this transformation.\na - vector containing the rate coefficients for each independent jump in the system\nh - vector of vectors containing the jump functions \nX - basic semialgebraic set enclosing the state space of the process\niv - independent variable of the process (usually time)\ncontrols - vector of control variables (empty if there are none)\npoly_vars - Dict mapping symbolic variables created by Catalyst.jl or ModelingToolkit.jl to generated PolyVar placeholders.\n\n\n\n\n\n","category":"type"},{"location":"functionalities/#MarkovBounds.ReactionProcess","page":"Functionalities","title":"MarkovBounds.ReactionProcess","text":"ReactionProcess(rn::ReactionSystem, params = Dict())\n\nconstructor returns ReactionProcess object generated from Catalyst.jl ReactionSystem object with given parameters. The fields of ReactionProcess objects are\n\nReactionSystem- underlying ReactionSystem object as generated by Catalyst.jl\nJumpProcess - JumpProcess object describing a JumpProcess that is equivalent to the stochastic reaction network described by ReactionSystem\nspecies_to_index - Dictionary mapping chemical species to its internally used variable speciestoindex\nspecies_to_state - Dictionary mapping species to equivalent state in the JumpProcess\nstate_to_species - Dictionary mapping state in JumpProcess to species in reaction network\n\n\n\n\n\n","category":"type"},{"location":"functionalities/#MarkovBounds.DiffusionProcess","page":"Functionalities","title":"MarkovBounds.DiffusionProcess","text":"DiffusionProcess(x, f, σ, X = FullSpace();\n                 iv = PV{true}(\"t\"), controls = [], poly_vars = Dict())\n\nconstructor returns DiffusionProcess object with fields\n\nx - vector containing the system state. Can be specified both as PolyVar type object       from DynamicPolynomials.jl or Num type object generated by Catalyst.jl/ModelingToolkit.jl.        In the latter case, PolyVar variables with analogous names are generated automatically and       a dictionary is assembled that keeps track of this transformation.\nf - vector of drift coefficients for each state\nσ - diffusion matrix of the process\nX - basic semialgebraic set enclosing the state space of the process\niv - independent variable of the process (usually time)\ncontrols - vector of control variables (empty if there are none)\npoly_vars - Dict mapping symbolic variables created by Catalyst.jl or ModelingToolkit.jl to generated PolyVar placeholders.\n\n\n\n\n\n","category":"type"},{"location":"functionalities/#MarkovBounds.JumpDiffusionProcess","page":"Functionalities","title":"MarkovBounds.JumpDiffusionProcess","text":"JumpDiffusionProcess(x, a, h, f, σ, X = FullSpace()\n                     iv = PV{true}(\"t\"), controls = [], poly_vars = Dict())\n\nconstructor returns JumpDiffusionProcess object with fields\n\nx - vector containing the system state. Can be specified both as PolyVar type object       from DynamicPolynomials.jl or Num type object generated by Catalyst.jl/ModelingToolkit.jl.        In the latter case, PolyVar variables with analogous names are generated automatically and       a dictionary is assembled that keeps track of this transformation.\na - vector containing the rate coefficients for each independent jump in the system\nh - vector of vectors containing the jump functions \nf - vector of drift coefficients for each state\nσ - diffusion matrix of the process\nX - basic semialgebraic set enclosing the state space of the process\niv - independent variable of the process (usually time)\ncontrols - vector of control variables (empty if there are none)\npoly_vars - Dict mapping symbolic variables created by Catalyst.jl or ModelingToolkit.jl to generated PolyVar placeholders.\n\n\n\n\n\n","category":"type"},{"location":"functionalities/#MarkovBounds.ControlProcess","page":"Functionalities","title":"MarkovBounds.ControlProcess","text":"ControlProcess(MP::MarkovProcess, T::Real, U, obj, PCs = [], TCs = [], dis_fac = 0)\n\nconstructor returns object of type ControlProcess with fields\n\nMP - MarkovProcess to be controlled\nT - length of the time horizon (can be Inf)\nU - closed basic semialgebraic set describing admissible control actions\nPathChanceConstraints - Array of chance path constraints\nTerminalChanceConstraints - Array of terminal chance constraints\ndiscount_factor - discount factor for accumulating stage cost\n\n\n\n\n\n","category":"type"},{"location":"functionalities/#MarkovBounds.LagrangeMayer","page":"Functionalities","title":"MarkovBounds.LagrangeMayer","text":"LagrangeMayer\n\na type used to specify an objective function consisting of a Lagrange and Mayer term, i.e., mathbbEleft int_0^T l(x(t) u(t))  dt + m(x(T))right. The Lagrange and Mayer term are specified in terms of polynomial functions l  X times U to mathbbR and m  X to mathbbR, respectively.\n\nFields: \n\nl - AbstractPolynomialLike determining the Lagrange term\nm - AbstractPolynomialLike determining the Mayer term\n\nIf only a Lagrange or Mayer term is neede for specification of the objective function, one can make use of the functions Lagrange(l::AbstractPolynomialLike) and Mayer(m::AbstractPolynomialLike) for more convenient model specification.\n\n\n\n\n\n","category":"type"},{"location":"functionalities/#MarkovBounds.TerminalSetProbability","page":"Functionalities","title":"MarkovBounds.TerminalSetProbability","text":"TerminalSetProbability\n\na type used to specify an objective function quantifiying the probability for a supported Markov process  to occupy a specified closed basic semialgebraic set at the end of the control horizon specified in a ControlProcess object. \n\nFields: \n\nX - basic semialgebraic set whose occupation probability is to be quantified at the end of the control horizon\n\n\n\n\n\n","category":"type"},{"location":"functionalities/#MarkovBounds.ExitProbability","page":"Functionalities","title":"MarkovBounds.ExitProbability","text":"ExitProbability\n\na type used to specify an objective function quantifiying the probability for a supported Markov process  to exit a specified closed basic semialgebraic set on the time horizon specified in a ControlProcess object. \n\nFields: \n\nX - basic semialgebraic set whose exit probability is to be quantified\n\n\n\n\n\n","category":"type"},{"location":"functionalities/#Bounds-on-Stationary-Moments-of-Markov-Processes","page":"Functionalities","title":"Bounds on Stationary Moments of Markov Processes","text":"","category":"section"},{"location":"functionalities/","page":"Functionalities","title":"Functionalities","text":"stationary_polynomial(MP::MarkovProcess, v::APL, d::Int, solver)\nstationary_mean(MP::MarkovProcess, v::APL, d::Int, solver)\nstationary_mean(rn::ReactionSystem, S0::Dict, S, d::Int, solver,\n                scales = Dict(s => 1 for s in speceies(rn));\n                auto_scaling = false)\nstationary_variance(MP::MarkovProcess, v::APL, d::Int, solver)\nstationary_variance(rn::ReactionSystem, S0, x, d::Int, solver,\n                    scales = Dict(s => 1 for s in speceies(rn));\n                    auto_scaling = false)\nstationary_covariance_ellipsoid(MP::MarkovProcess, v::Vector{<:APL}, d::Int, solver)\nstationary_covariance_ellipsoid(rn::ReactionSystem, S0::Dict, S::AbstractVector, d::Int, solver,\n                                scales = Dict(s => 1 for s in speceies(rn));\n                                auto_scaling = false)","category":"page"},{"location":"functionalities/#MarkovBounds.stationary_polynomial-Tuple{MarkovProcess, AbstractPolynomialLike, Int64, Any}","page":"Functionalities","title":"MarkovBounds.stationary_polynomial","text":"stationary_polynomial(MP::MarkovProcess, v::APL, d::Int, solver)\n\nreturns a lower bound on the expecation of a polynomial observables v(x) at steady state of the Markov process MP. The bound is computed based on an SOS program over a polynomial of degree at most d; the bounds can be tightened by increasing d. The program is solved with solver.\n\n\n\n\n\n","category":"method"},{"location":"functionalities/#MarkovBounds.stationary_mean-Tuple{MarkovProcess, AbstractPolynomialLike, Int64, Any}","page":"Functionalities","title":"MarkovBounds.stationary_mean","text":"stationary_mean(MP::MarkovProcess, v::APL, d::Int, solver)\n\nreturns lower and upper bound on the observable v(x) at steady state of the Markov process MP. Bounds are computed based on SOS programs over a polynomial of degree at most d; the bounds can be tightened by increasing d. The program is solved with solver.\n\n\n\n\n\n","category":"method"},{"location":"functionalities/#MarkovBounds.stationary_mean","page":"Functionalities","title":"MarkovBounds.stationary_mean","text":"stationary_mean(rn::ReactionSystem, S0::Dict, S, d::Int, solver,\n\t\tscales = Dict(s => 1 for s in species(rn));\n\t\tauto_scaling = false)\n\nreturns lower and upper bound on the mean of species S of the reaction network rn with initial condition S0 (for all species!). The bound is based on an SOS program of order d solved via solver; the bounds can be tightened by increasing d.\n\nFor numerical stability, it is recommended to provide scales of the expected magnitude of molecular counts for the different species at steady state. If the system is closed it is also possible to enable auto_scaling which will find the maximum molecular counts for each species under stoichiometry constraints (via LP).\n\nIf the initial condition of the reaction network under investigation is unknown or irrelevant, simply call\n\nstationary_mean(rn::ReactionSystem, S, d::Int, solver,\n\t\tscales = Dict(s => 1 for s in species(rn))).\n\n\n\n\n\n","category":"function"},{"location":"functionalities/#MarkovBounds.stationary_variance-Tuple{MarkovProcess, AbstractPolynomialLike, Int64, Any}","page":"Functionalities","title":"MarkovBounds.stationary_variance","text":"stationary_variance(MP::MarkovProcess, v::APL, d::Int, solver)\n\nreturns SOS program of degree d for computation of an upper bound on the variance of a polynomial observables v at steady state of the Markov process MP.\n\n\n\n\n\n","category":"method"},{"location":"functionalities/#MarkovBounds.stationary_variance","page":"Functionalities","title":"MarkovBounds.stationary_variance","text":"stationary_variance(rn::ReactionSystem, S0, x, d::Int, solver,\n\t\t    scales = Dict(s => 1 for s in species(rn));\n\t\t    auto_scaling = false)\n\nreturns upper bound on the variance of species S of the reaction network rn with initial condition S0 (for all species!). The bound is based on an SOS program of degree d solved via solver; the bound can be tightened by increasing d.\n\nFor numerical stability, it is recommended to provide scales of the expected magnitude of molecular counts for the different species at steady state. If the system is closed it is also possible to enable auto_scaling which will find the maximum molecular counts for each species under stoichiometry constraints (via LP).\n\nIf the initial condition of the reaction network under investigation is unknown or irrelevant, simply call\n\nstationary_variance(rn::ReactionSystem, S, d::Int, solver,\n\t\t    scales = Dict(s => 1 for s in species(rn)))\n\n\n\n\n\n","category":"function"},{"location":"functionalities/#MarkovBounds.stationary_covariance_ellipsoid-Tuple{MarkovProcess, Vector{var\"#s30\"} where var\"#s30\"<:AbstractPolynomialLike, Int64, Any}","page":"Functionalities","title":"MarkovBounds.stationary_covariance_ellipsoid","text":"stationary_covariance_ellipsoid(MP::MarkovProcess, v::Vector{<:APL}, d::Int, solver)\n\nreturns an upper on the volume of the covariance ellipsoid of a vector of polynomial observables v(x), i.e., textdet(mathbbE v(x)v(x)^top - mathbbEv(x) mathbbEv(x)^top), at steady state of the Markov process MP. The bounds are computed via an SOS program of degree d, hence can be tightened by increasing d. This computation requires a solver that can handle exponential cone constraints.\n\n\n\n\n\n","category":"method"},{"location":"functionalities/#MarkovBounds.stationary_covariance_ellipsoid","page":"Functionalities","title":"MarkovBounds.stationary_covariance_ellipsoid","text":"stationary_covariance_ellipsoid(rn::ReactionSystem, S0::Dict, S::AbstractVector, d::Int, solver,\n\t\t\t\tscales = Dict(s => 1 for s in species(rn));\n\t\t\t\tauto_scaling = false)\n\nreturns an upper on the volume of the covariance ellipsoid of any subset S of the chemical species in the reaction network rn, i.e., textdet(mathbbESS^top - mathbbES mathbbES^top), at steady state of the associated jump process. The reaction network is assumed to have the deterministic initial state S0 (all species must be included here!). The bounds are computed via an SOS program of degree d, hence can be tightened by increasing d. This computation requires a solver that can deal with exponential cone constraints.\n\nFor numerical stability, it is recommended to provide scales of the expected magnitude of molecular counts for the different species at steady state. If the system is closed it is also possible to enable auto_scaling which will find the maximum molecular counts for each species under stoichiometry constraints (via LP).\n\nIf the initial condition of the reaction network under investigation is unknown or irrelevant, simply call\n\nstationary_covariance_ellipsoid(rn::ReactionSystem, S, d::Int, solver,\n\t\t\t\tscales = Dict(s => 1 for s in species(rn)))\n\n\n\n\n\n","category":"function"},{"location":"functionalities/#Bounds-on-Transient-Moments-of-Markov-Processes","page":"Functionalities","title":"Bounds on Transient Moments of Markov Processes","text":"","category":"section"},{"location":"functionalities/","page":"Functionalities","title":"Functionalities","text":"transient_polynomial(MP::MarkovProcess, μ0::Dict, v::APL, d::Int, trange::AbstractVector{<:Real}, solver)\ntransient_mean(MP::MarkovProcess, μ0::Dict, x::APL, d::Int, trange::AbstractVector{<:Real}, solver)\ntransient_mean(rn::ReactionSystem, S0::Dict, S, d::Int, trange::AbstractVector{<:Number}, solver,\n            scales = Dict(s => 1 for s in speceies(rn));\n            auto_scaling = false)\ntransient_variance(MP::MarkovProcess, μ0::Dict, v::APL, d::Int, trange::AbstractVector{<:Real}, solver)\ntransient_variance(rn::ReactionSystem, S0::Dict, S, d::Int, trange::AbstractVector{<:Real}, solver,\n            scales = Dict(s => 1 for s in speceies(rn));\n            auto_scaling = false)\ntransient_covariance_ellipsoid(MP::MarkovProcess, μ0::Dict, v::Vector{APL}, d::Int, trange::AbstractVector{<:Real}, solver)\ntransient_covariance_ellipsoid(rn::ReactionSystem, S0::Dict, S::AbstractVector, d::Int, trange::AbstractVector{<:Real}, solver,\n            scales = Dict(s => 1 for s in speceies(rn));\n            auto_scaling = false)","category":"page"},{"location":"functionalities/#MarkovBounds.transient_polynomial-Tuple{MarkovProcess, Dict, AbstractPolynomialLike, Int64, AbstractVector{var\"#s30\"} where var\"#s30\"<:Real, Any}","page":"Functionalities","title":"MarkovBounds.transient_polynomial","text":"transient_polynomial(MP::MarkovProcess, μ0::Dict, v::APL, d::Int, trange::AbstractVector{<:Real}, solver)\n\nreturns a lower bound on mathbbEv(x(T)) where v is a polynomial and x(T) the state of the Markov process MP at time T = trange[end]. μ0 encodes the distribution of the initial state of the process in terms of its moments; specifically, it maps monomials to the respective moments of the initial distribution. trange is an ordered collection of time points used to discretize the time horizon 0T, i.e., T = trange[end]. Populating trange and increasing d improves the computed bound.\n\n\n\n\n\n","category":"method"},{"location":"functionalities/#MarkovBounds.transient_mean-Tuple{MarkovProcess, Dict, AbstractPolynomialLike, Int64, AbstractVector{var\"#s30\"} where var\"#s30\"<:Real, Any}","page":"Functionalities","title":"MarkovBounds.transient_mean","text":"transient_mean(MP::MarkovProcess, μ0::Dict, x::APL, d::Int, trange::AbstractVector{<:Real}, solver)\n\nreturns a lower and upper bound on mathbbEv(x(T)) where v is a polynomial and x(T) the state of the Markov process MP at time T = trange[end]. μ0 encodes the distribution of the initial state of the process in terms of its moments; specifically, it maps monomials to the respective moments of the initial distribution. trange is an ordered collection of time points used to discretize the time horizon 0T, i.e., T = trange[end]. Populating trange and increasing d improves the computed bounds.\n\n\n\n\n\n","category":"method"},{"location":"functionalities/#MarkovBounds.transient_mean","page":"Functionalities","title":"MarkovBounds.transient_mean","text":"transient_mean(rn::ReactionSystem, S0::Dict, S, d::Int, trange::AbstractVector{<:Number}, solver,\n\t\tscales = Dict(s => 1 for s in species(rn));\n\t\tauto_scaling = false)\n\nreturns a lower and upper bound on the mean of the molecular count of species S in reaction network rn at time T = trange[end]. S0 refers to the deterministic initial state of the reaction system (including all species!). trange is an ordered collection of time points used to discretize the time horizon 0T, i.e., T = trange[end]. Populating trange and increasing d improves the computed bounds.\n\nFor numerical stability, it is recommended to provide scales of the expected magnitude of molecular counts for the different species at steady state. If the system is closed it is also possible to enable auto_scaling which will find the maximum molecular counts for each species under stoichiometry constraints (via LP).\n\n\n\n\n\n","category":"function"},{"location":"functionalities/#MarkovBounds.transient_variance-Tuple{MarkovProcess, Dict, AbstractPolynomialLike, Int64, AbstractVector{var\"#s30\"} where var\"#s30\"<:Real, Any}","page":"Functionalities","title":"MarkovBounds.transient_variance","text":"transient_variance(MP::MarkovProcess, μ0::Dict, v::APL, d::Int, trange::AbstractVector{<:Real}, solver)\n\nreturns an upper bound on mathbbEv(x(T))^2 - mathbbEv(x(T))^2 where v is a polynomial and x(T) the state of the Markov process MP at time T = trange[end].\n\n\n\n\n\n","category":"method"},{"location":"functionalities/#MarkovBounds.transient_variance","page":"Functionalities","title":"MarkovBounds.transient_variance","text":"transient_variance(rn::ReactionSystem, S0::Dict, S, d::Int, trange::AbstractVector{<:Real}, solver,\n\t\t    scales = Dict(s => 1 for s in species(rn));\n\t\t\tauto_scaling = false)\n\nreturns an upper bound on the variance of species S in the reaction network rn at time T = trange[end]. S0 refers to the deterministic initial state of the reaction system (including all species!). trange is an ordered collection of time points used to discretize the time horizon 0T, i.e., T = trange[end]. Populating trange and increasing d improves the computed bounds.\n\nFor numerical stability, it is recommended to provide scales of the expected magnitude of molecular counts for the different species at steady state. If the system is closed it is also possible to enable auto_scaling which will find the maximum molecular counts for each species under stoichiometry constraints (via LP).\n\n\n\n\n\n","category":"function"},{"location":"functionalities/#MarkovBounds.transient_covariance_ellipsoid-Tuple{MarkovProcess, Dict, Vector{AbstractPolynomialLike}, Int64, AbstractVector{var\"#s30\"} where var\"#s30\"<:Real, Any}","page":"Functionalities","title":"MarkovBounds.transient_covariance_ellipsoid","text":"transient_covariance_ellipsoid(MP::MarkovProcess, μ0::Dict, v::Vector{APL}, d::Int, trange::AbstractVector{<:Real}, solver)\n\nreturns an upper bound on the volume of the covariance ellipsoid textdet(mathbbEv(x(T))v(x(T))^top - mathbbEv(x(T)) mathbbEv(x(T))^top), where v is a polynomial and x(T) the state of the Markov process MP at time T = trange[end].\n\n\n\n\n\n","category":"method"},{"location":"functionalities/#MarkovBounds.transient_covariance_ellipsoid","page":"Functionalities","title":"MarkovBounds.transient_covariance_ellipsoid","text":"transient_covariance_ellipsoid(rn::ReactionSystem, S0::Dict, S::AbstractVector, d::Int, trange::AbstractVector{<:Real}, solver,\n\t\t\t\t\t\tscales = Dict(s => 1 for s in species(rn));\n\t\t\t\t\t\tauto_scaling = false)\n\nreturns an upper bound on the volume of the covariance ellipsoid associated with any collection of chemical species in the reaction network rn at time T = trange[end]. S0 refers to the deterministic initial state of the reaction system (including all species!). trange is an ordered collection of time points used to discretize the time horizon 0T, i.e., T = trange[end]. Populating trange and increasing d improves the computed bounds.\n\nFor numerical stability, it is recommended to provide scales of the expected magnitude of molecular counts for the different species at steady state. If the system is closed it is also possible to enable auto_scaling which will find the maximum molecular counts for each species under stoichiometry constraints (via LP).\n\n\n\n\n\n","category":"function"},{"location":"functionalities/#Bounds-on-Stochastic-Optimal-Control-Problems","page":"Functionalities","title":"Bounds on Stochastic Optimal Control Problems","text":"","category":"section"},{"location":"functionalities/","page":"Functionalities","title":"Functionalities","text":"optimal_control(CP::ControlProcess, μ0::Dict, d::Int, trange::AbstractVector{<:Real}, solver)","category":"page"},{"location":"functionalities/#MarkovBounds.optimal_control-Tuple{ControlProcess, Dict, Int64, AbstractVector{var\"#s30\"} where var\"#s30\"<:Real, Any}","page":"Functionalities","title":"MarkovBounds.optimal_control","text":"optimal_control(CP::ControlProcess, μ0::Dict, d::Int, trange::AbstractVector{<:Real}, solver)\n\nreturns a lower bound on the objective value of the (stochastic) optimal control problem specified by CP. μ0 encodes information about the distribution of the initial state of the process; specifically, μ0 maps a given monomial to the corresponding moment of the initial distribution. trange refers to an ordered set of time points discretizing the control horizon. trange[end] should coincide with the end of the control horizon, i.e., trange[end] = Inf in case of an infinite horizon problem. The bound is computed via a SOS program of degree d solved with an appropriate method given by solver.\n\nThe bound can be tightened by populating trange or increasing d.\n\n\n\n\n\n","category":"method"},{"location":"background/#background","page":"Background","title":"Background on Moment Bounding Schemes","text":"","category":"section"},{"location":"background/#Polynomial-Jump-Diffusion-Processes","page":"Background","title":"Polynomial Jump-Diffusion Processes","text":"","category":"section"},{"location":"background/","page":"Background","title":"Background","text":"A jump-diffusion process is dynamical system combining a deterministic evolution of the system state, called drift, with a stochastic vibrations driven by a Brownian Motion, called diffusion, and another stochastic contribution modeling discrete changes driven by Poisson counters, called jumps. The evolution of the process state x_t over time t through its state space X subset mathbbR^n is governed by the following stochastic differential equation","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"    dx_t = f(x_t)  dt + g(x_t)  dW_t + sum_i=1^n_R h(x_t)  dN_a_i(x_t)","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"where W_t denotes a standard mathbbR^m-Brownian motion and N_a_i(x_t) a standard Poisson counter with rate a_i. The problem data is considered","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"drift coefficient fmathbbR^n to mathbbR^n\ndiffusion matrix gg^top   mathbbR^n to mathbbR^ntimes n (or diffusion coefficient $ g:\\mathbb{R}^n \\to \\mathbb{R}^{n \\times m} $)\narrival rates a_i  mathbbR^n to mathbbR, i  = 1dots n_R\njumps h_imathbbR^n to mathbbR^n, i  = 1dots n_R\nstate space X ","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"A fundamental assumption in MarkovBounds.jl (and to a large extent moment bounding schemes inherently) is that the data of the jump-diffusion process under investigation can be fully characterized in terms of polynomials, i.e., all functions listed above are polynomials (component-wise) and the state space is (or can at least be outer approximated by) a basic closed semialgebraic set. Throughout, we will refer to processes that satisfies this assumption as polynomial jump-diffusion processes. A wide range of problems, in particular in the realm of stochastic chemical kinetics, lend themselves to be modeled in terms of polynomial jump-diffusion processes; if this assumption, however, is not satisfied, a simple but limited workaround is to find approximations of the data in terms of polynomials and apply the moment bounding scheme in a second step.","category":"page"},{"location":"background/#Moment-Bounding-Schemes","page":"Background","title":"Moment Bounding Schemes","text":"","category":"section"},{"location":"background/","page":"Background","title":"Background","text":"The core idea behind moment bounding schemes is rather simple. But to explain it, we first need to establish some notation: Let y_i(t) = mathbbE left prod_k=1^n x_k(t)^i_k right denote the moment corresponding to the multi-index i in mathbbN_0^n of a polynomial jump-diffusion process as defined the previous section. Similarly, let mathbfy_q(t)  be the truncated sequence of all multivariate moments of the process up to order q in mathbbN, i.e., mathbfy_q(t) =  y_i(t)  i leq q . Due to the notorious moment closure problem, mathbfy_q(t) cannot in general be computed directly via simple simulation. To circumvent this issue, moment bounding schemes seek to identify a proxy for mathbfy_q(t), say tildemathbfy_q(t), which minimizes (or maximizes if upper bound is sought) a certain statistic of the process under investigation, while ensuring that tildemathbfy_q(t) remains in certain ways consistent with the process under investigation (we will see shortly what that means concretely). Slightly more formally, we seek to solve an optimization problem of the form","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"beginaligned \n    inf_tildemathbfy_q quad int_0^T l^top tildemathbfy_q(t)  dt + m^top tildemathbfy_q(T) \n    textst quad  tildemathbfy_q text satisfies necessary consistency conditions \nendaligned","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"The key insight underpinning all moment bounding schemes now is that a suitable choice of \"necessary consistency conditions\" turns the above \"pseudo\" optimization problem into a convex optimization problem known as generalized moment problem. The practical value of this observations lies in the fact that strong convex relaxations of these generalized moment problems are easily constructed and they can be readily solved with off-the-shelve semidefinite programming (SDP) solvers such as Mosek, SeDuMi or SDPT3. ","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"But what are these \"necessary consistency conditions\"? We won't answer this question in detail here but provide some examples and intuition for their nature. The above mentioned consistency conditions can be loosely classified as a) reflecting the dynamics of the underlying process and b) the support of its distribution. Conditions of type a) are affine relations that the moments of process have to satisfy. To derive these conditions, note that the (extended) infinitesimal generator of the process","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"    beginaligned\n        mathcalA  w(tz) mapsto lim_hto 0^+ fracmathbbE_zw(t + hx(t + h)) - w(tz)h \n                                = frac partial w(tz) partial t  + f(z)^top nabla_z w(tz) + textTrleft(gg^top(z) nabla_z^2 w(tz) right) + sum_i=1^n_R a_i(z) w(t h_i(z))\n    endaligned","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"maps polynomials to polynomials under the assumption of a polynomial jump diffusion process. The moments of a polynomial jump-diffusion process accordingly follow linear, albeit generally underdetermined, dynamics:","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"    fracddtmathbbEleftprod_k=1^n x_k^i_k(t) right = mathbbEleft mathcalAprod_k=1^n x_k^i_k(t) right iff fracdy_idt(t) = a_i^top mathbfy_q(t)","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"From this point we could in principle derive more tractable conditions; however, since this requires introduction of more technical terms and we believe it does not contribute to building better intuition, we will refer the interested reader to the references listed below instead of going through the construction here.","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"Conditions of type b) impose positive semidefiniteness of certain moment matrices. To understand why such conditions are in fact somehow natural, consider a one-dimensional process x(t) and a vector of the monomial basis b(x) = 1 x x^2 dots x^d. Then clearly,  the moment matrix","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"    mathbbEleft b(x(t)) b(x(t))^top right = beginbmatrix 1  y_1(t)  y_2(t)cdots  y_d(t) \n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t    y_1(t)  y_2(t)  y_3(t)  cdots  y_d+1(t) \n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t    y_2(t)  y_3(t)   ddots   y_d+2(t) \n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t    vdots  vdots    vdots \n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t    y_d(t)  y_d+1(t)  y_d+2(t)  cdots  y_2d(t) \n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t    endbmatrix","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"must be positive semidefinite as the left-hand-side is. This argument generalizes immediately to the multivariate case. The condition,","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"    mathbbEleft b(x(t)) b(x(t))^top right= int_X b(x) b(x)^top  dP(xt) succeq 0","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"can be viewed as reflecting non-negativity of the probability measure P(cdott) describing the distribution of the process state at time t. With this intuition in mind, it follows further that for any polynomial p which is non-negative on the state space X, the condition","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"    mathbbEp(x(t))b(x(t)) b(x(t))^top succeq 0","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"must hold, reflecting the support of the probability distribution P(cdott) on the state space X. Further observe that conditions of this form translate directly into Linear Matrix Inequalities on the moments of the process, suggesting why the resulting problems can be tackled via SDP. ","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"For more details and technicalities on moment bounding schemes, please consult the references below.","category":"page"},{"location":"background/#References","page":"Background","title":"References","text":"","category":"section"},{"location":"background/","page":"Background","title":"Background","text":"[1] Holtorf, Flemming, and Paul I. Barton. \"Tighter bounds on transient moments of stochastic chemical systems.\" arXiv preprint arXiv:2104.01309 (2021).","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"[2] Kuntz, Juan, et al. \"Bounding the stationary distributions of the chemical master equation via mathematical programming.\" The Journal of chemical physics 151.3 (2019): 034109.","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"[3] Dowdy, Garrett R., and Paul I. Barton. \"Dynamic bounds on stochastic chemical kinetic systems using semidefinite programming.\" The Journal of chemical physics 149.7 (2018): 074103.","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"[4] Dowdy, Garrett R., and Paul I. Barton. \"Bounds on stochastic chemical kinetic systems at steady state.\" The Journal of chemical physics 148.8 (2018): 084106.","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"[5] Sakurai, Yuta, and Yutaka Hori. \"Bounding transient moments of stochastic chemical reactions.\" IEEE Control Systems Letters 3.2 (2018): 290-295.","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"[6] Sakurai, Yuta, and Yutaka Hori. \"Optimization-based synthesis of stochastic biocircuits with statistical specifications.\" Journal of The Royal Society Interface 15.138 (2018): 20170709.","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"[7] Sakurai, Yuta, and Yutaka Hori. \"A convex approach to steady state moment analysis for stochastic chemical reactions.\" 2017 IEEE 56th Annual Conference on Decision and Control (CDC). IEEE, 2017.","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"[8] Ghusinga, Khem Raj, et al. \"Exact lower and upper bounds on stationary moments in stochastic biochemical systems.\" Physical biology 14.4 (2017): 04LT01","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"[9] Kuntz, Juan, et al. \"Bounding stationary averages of polynomial diffusions via semidefinite programming.\" SIAM Journal on Scientific Computing 38.6 (2016): A3891-A3920.","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"[10] Lasserre, Jean B. Moments, positive polynomials and their applications. Vol. 1. World Scientific, 2009.","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"[11] Savorgnan, Carlo, Jean B. Lasserre, and Moritz Diehl. \"Discrete-time stochastic optimal control via occupation measures and moment relaxations.\" Proceedings of the 48h IEEE Conference on Decision and Control (CDC) held jointly with 2009 28th Chinese Control Conference. IEEE, 2009.","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"[12] Lasserre, Jean B., Tomas Prieto‐Rumeau, and Mihail Zervos. \"Pricing a class of exotic options via moments and SDP relaxations.\" Mathematical Finance 16.3 (2006): 469-494.","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"[13] Lasserre, Jean B. \"Global optimization with polynomials and the problem of moments.\" SIAM Journal on optimization 11.3 (2001): 796-817.","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"[14] Helmes, Kurt, Stefan Röhl, and Richard H. Stockbridge. \"Computing moments of the exit time distribution for Markov processes by linear programming.\" Operations Research 49.4 (2001): 516-530.","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"[15] Schwerer, Elizabeth. \"A linear programming approach to the steady-state analysis of reflected Brownian motion.\" (2001): 341-368.","category":"page"},{"location":"background/","page":"Background","title":"Background","text":"[16] Bhatt, Abhay G., and Vivek S. Borkar. \"Occupation measures for controlled Markov processes: Characterization and optimality.\" The Annals of Probability (1996): 1531-1562.","category":"page"},{"location":"tutorials/birth_death_process/#Analysis-of-a-Birth-Death-Processes","page":"Analysis of a Birth-Death Processes","title":"Analysis of a Birth-Death Processes","text":"","category":"section"},{"location":"tutorials/birth_death_process/","page":"Analysis of a Birth-Death Processes","title":"Analysis of a Birth-Death Processes","text":"In this example we wish to study the statistics of the simple nonlinear birth-death process","category":"page"},{"location":"tutorials/birth_death_process/","page":"Analysis of a Birth-Death Processes","title":"Analysis of a Birth-Death Processes","text":"∅ → A\n2A → A","category":"page"},{"location":"tutorials/birth_death_process/","page":"Analysis of a Birth-Death Processes","title":"Analysis of a Birth-Death Processes","text":"following mass-action kinetics. To define the underlying jump process it is convenient to utilize Catalyst.jl's functionality and simply define a reaction network with the above reactions.","category":"page"},{"location":"tutorials/birth_death_process/","page":"Analysis of a Birth-Death Processes","title":"Analysis of a Birth-Death Processes","text":"birth_death = @reaction_network begin\n    1.0, ∅ --> A\n    0.01, 2A --> A\nend","category":"page"},{"location":"tutorials/birth_death_process/","page":"Analysis of a Birth-Death Processes","title":"Analysis of a Birth-Death Processes","text":"We will need to make reference to the species A in the network at several occasions. We therefore extract the symbolic variable using Catalyst.jl's species function.","category":"page"},{"location":"tutorials/birth_death_process/","page":"Analysis of a Birth-Death Processes","title":"Analysis of a Birth-Death Processes","text":"A = species(birth_death)[1]","category":"page"},{"location":"tutorials/birth_death_process/","page":"Analysis of a Birth-Death Processes","title":"Analysis of a Birth-Death Processes","text":"Throughout, we will further assume that the initial state of the process is known with deterministic certainty. The initial condition is supplied in form of a dictionary mapping the symbolic variable of all species in the process to their initial value. In this case, we assume that the initial count of species A is 2.","category":"page"},{"location":"tutorials/birth_death_process/","page":"Analysis of a Birth-Death Processes","title":"Analysis of a Birth-Death Processes","text":"A0 = Dict(A => 2.0)","category":"page"},{"location":"tutorials/birth_death_process/","page":"Analysis of a Birth-Death Processes","title":"Analysis of a Birth-Death Processes","text":"On a technical note, it shall also be emphasized that in biochemical applications it is very important to provide scales for the molecular counts of the different species in the system. Otherwise numerical instabilities will likely cause inaccurate solutions. The scales are provided in the same format as the initial conditions. The scales need not be accurate and can be obtained in many sensible ways, for example by looking at a single trajectory of the network or even at the deterministic rate-law model. For closed systems, MarkovBoundsSOS allows to compute scales based on the stoichiometry in the system.","category":"page"},{"location":"tutorials/birth_death_process/","page":"Analysis of a Birth-Death Processes","title":"Analysis of a Birth-Death Processes","text":"A_scale = Dict(A => 10.0)","category":"page"},{"location":"tutorials/birth_death_process/","page":"Analysis of a Birth-Death Processes","title":"Analysis of a Birth-Death Processes","text":"With these pieces of input data, we can start analyzing the statistics of the stochastic reaction network/jump process.","category":"page"},{"location":"tutorials/birth_death_process/","page":"Analysis of a Birth-Death Processes","title":"Analysis of a Birth-Death Processes","text":"For example, we can find upper and lower bounds on the mean count of species A with respect to the stationary distribution of the process. This can be done by calling the function stationary_mean specifying the reaction network, the species of which bounds are sought, an order for the relaxation used for computing the bounds, an appropriate solver and (if desired) scales for the different species as inputs. In our case the reaction network is the birth-death network defined above and we care species A. The order of the relaxation used is left to the user to decide on a trade-off between computational cost and bound quality; the larger the order is chosen, the better the bounds become (in absence of numerical issues). It is generally advisable to start with low orders (2-6) and only go beyond these values if necessary as numerical instabilities become more pronounced issues at high orders. While any SDP solver supported by JuMP (https://jump.dev/JuMP.jl/stable/installation/#Supported-solvers) can be used, we recommend with sticking with the interior-point based solvers such as Mosek, SeDuMi, SDPA, or SDPT3. With all these pieces in place, the bounds can be computed by a simple function call:","category":"page"},{"location":"tutorials/birth_death_process/","page":"Analysis of a Birth-Death Processes","title":"Analysis of a Birth-Death Processes","text":"mean_bounds = []\norders = [2, 4, 6, 8]\nfor relaxation_order in orders\n    b = stationary_mean(birth_death, A, relaxation_order, Mosek.Optimizer, A_scale)\n    push!(mean_bounds, b)\nend","category":"page"},{"location":"tutorials/birth_death_process/","page":"Analysis of a Birth-Death Processes","title":"Analysis of a Birth-Death Processes","text":"(Image: )","category":"page"},{"location":"tutorials/birth_death_process/","page":"Analysis of a Birth-Death Processes","title":"Analysis of a Birth-Death Processes","text":"Similarly, we can compute an upper bound on the variance of the stationary distribution of the process.","category":"page"},{"location":"tutorials/birth_death_process/","page":"Analysis of a Birth-Death Processes","title":"Analysis of a Birth-Death Processes","text":"var_ub = []\norders = [2, 4, 6, 8]\nfor order in orders\n    b = stationary_variance(birth_death, A, order, Mosek.Optimizer, A_scale)\n    push!(var_ub, b)\nend","category":"page"},{"location":"tutorials/birth_death_process/","page":"Analysis of a Birth-Death Processes","title":"Analysis of a Birth-Death Processes","text":"(Image: )","category":"page"},{"location":"tutorials/birth_death_process/","page":"Analysis of a Birth-Death Processes","title":"Analysis of a Birth-Death Processes","text":"While a lower bound of the variance can not be computed directly, we can use the fact that we can compute bounds on the expecation of any polynomial of the system state with respect to the stationary distribution. Accordingly, we can simply compute a lower bound on 𝔼[A²] and combine this with the previously computed upper bound on 𝔼[A] to find a valid lower bound on the variance Var[A] = 𝔼[A²] - 𝔼[A]². To that end, we first transform the reaction network into a ReactionProcess using the function reaction_process_setup. This ReactionProcess features a jump process that is equivalent to the reaction network, however, accounts for potential reaction invariants and applies scales to the state. Moreover, the ReactionProcess provides a map between the molecular species of the network on the states of the jump process for easy interpretation of the results.","category":"page"},{"location":"tutorials/birth_death_process/","page":"Analysis of a Birth-Death Processes","title":"Analysis of a Birth-Death Processes","text":"RP, x0 = reaction_process_setup(birth_death, A0, scales = A_scale)","category":"page"},{"location":"tutorials/birth_death_process/","page":"Analysis of a Birth-Death Processes","title":"Analysis of a Birth-Death Processes","text":"Now we can compute a lower bound on Var(A)","category":"page"},{"location":"tutorials/birth_death_process/","page":"Analysis of a Birth-Death Processes","title":"Analysis of a Birth-Death Processes","text":"var_lb = []\nfor order in orders\n    b = stationary_polynomial(RP.JumpProcess, RP.species_to_state[A]^2, order, Mosek.Optimizer)\n    push!(var_lb, b)\nend","category":"page"},{"location":"tutorials/birth_death_process/","page":"Analysis of a Birth-Death Processes","title":"Analysis of a Birth-Death Processes","text":"(Image: )","category":"page"},{"location":"tutorials/birth_death_process/","page":"Analysis of a Birth-Death Processes","title":"Analysis of a Birth-Death Processes","text":"Everything presented above generalizes to the problem of bounding the expectation of moments and related statistics along at any finite time. For example, we can find lower and upper bounds on the mean molecular count of species A after 10 seconds:","category":"page"},{"location":"tutorials/birth_death_process/","page":"Analysis of a Birth-Death Processes","title":"Analysis of a Birth-Death Processes","text":"`transient_mean(birth_death, A0, A, 4, [10.0], Mosek.Optimizer, A_scale)`","category":"page"},{"location":"tutorials/birth_death_process/","page":"Analysis of a Birth-Death Processes","title":"Analysis of a Birth-Death Processes","text":"These transient bounds can not only be improved by increasing the order of the relaxation but also by refining discretization of the temporal domain. This discretization is specified by providing an ordered list of time points in place of simply the time at which the bounds are to be evaluated. The last time point in this list refers to the time at which the bounds are evaluated.","category":"page"},{"location":"tutorials/birth_death_process/","page":"Analysis of a Birth-Death Processes","title":"Analysis of a Birth-Death Processes","text":"This way, we can for example evaluate bounds on the trajectories of the mean and the variance of the molecular count of species A by computing bounds at different time points:","category":"page"},{"location":"tutorials/birth_death_process/","page":"Analysis of a Birth-Death Processes","title":"Analysis of a Birth-Death Processes","text":"var_ub = []\nmean_bounds = []\nnT = 10 # number of intervals used to discretize the time domain\nTs = [0.1, 0.5, 1.0, 1.5, 2.0, 5.0, 10.0, 15.0, 20.0, 30.0, 40.0, 50.0]\nfor T in Ts\n    trange = range(0, T, length=nT+1)\n    b = transient_mean(birth_death, A0, A, 4, trange, Mosek.Optimizer, A_scale)\n    push!(mean_bounds, b)\n    b = transient_variance(birth_death, A0, A, 4, trange, Mosek.Optimizer, A_scale)\n    push!(var_ub, b)\nend","category":"page"},{"location":"tutorials/birth_death_process/","page":"Analysis of a Birth-Death Processes","title":"Analysis of a Birth-Death Processes","text":"This way, we generate the following bounds on the moment trajectories of the process. ","category":"page"},{"location":"tutorials/birth_death_process/","page":"Analysis of a Birth-Death Processes","title":"Analysis of a Birth-Death Processes","text":"(Image: )","category":"page"},{"location":"tutorials/birth_death_process/","page":"Analysis of a Birth-Death Processes","title":"Analysis of a Birth-Death Processes","text":"For more detailes on the code used in this example, please review this jupyter notebook.","category":"page"},{"location":"#MarkovBounds.jl","page":"Home","title":"MarkovBounds.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"MarkovBounds.jl is a Julia package seeking to automate the setup of moment bounding schemes for the analysis of jump-diffusion processes with the goal of enabling those unfamiliar with moment problems or optimization in general to apply moment bounding schemes regardless. To that end, MarkovBounds.jl automatically translates high-level problem data framing a jump-diffusion process as specified via convenient tools such as Catalyst.jl, Symbolics.jl/ModelingToolkit.jl or DynamicPolynomials.jl into sum-of-squares (SOS) programs and solve them via the existing optimization pipeline in Julia (see SumOfSquares.jl, JuMP and MathOptInterface.jl). The solution of said SOS programs are returned to the user in form of theoretically guaranteed bounds on moments and other key statistics of the process under investigation.","category":"page"},{"location":"","page":"Home","title":"Home","text":"(Image: program structure)","category":"page"},{"location":"#When-should-you-consider-using-moment-bounding-schemes?","page":"Home","title":"When should you consider using moment bounding schemes?","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Moment bounding schemes are limited by the capabilities of large-scale semidefinite programming. Given the current state-of-the-art, moment bounding schemes are practically limited to stochastic processes of low to medium dimensionality (< 10 states). Moreover, MarkovBounds.jl currently only supports processes in which the data can be fully characterized in terms of polynomials (see the Background section for details). ","category":"page"},{"location":"#Stationary-statistics","page":"Home","title":"Stationary statistics","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Moment bounding schemes have been found to perform remarkably well for the study of the stationary (or ergodic) statistics of stochastic processes. They have been found to provide high quality (often effectively tight) bounds on key statistics such as means, variances, Fano factors and more at a fraction of the computational time needed to provide similarly accurate sample statistics. ","category":"page"},{"location":"#Error-control","page":"Home","title":"Error control","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The analysis of jump-diffusion processes relies traditionally on brute force sampling of paths of the process such that a sufficiently large sample of such paths exihibits similar statistics as the generating process. However, even though this approach works remarkably well over a wide range of applications and powerful software tools supporting this approach exist (see e.g. DifferentialEquations.jl), it may break down in certain settings. Most notably, the generation of sample paths can become prohibitively expensive when the process under investigation is highly stiff and/or volatile, rendering simulation expensive and/or convergence of sample statistics to the true statistics slow. In those cases, practitioners tend to fall back on approximation techniques such as tau-leaping, moment closure approximations and many more, which recover tractability at the cost of introducing unverifiable assumptions and an unknown error. Moment bounding schemes can be used to quantify/bound this error by providing hard bounds on key statistics, both in the transient and stationary setting. ","category":"page"},{"location":"#Optimal-control-problems","page":"Home","title":"Optimal control problems","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Moment bounding schemes extend naturally to the application of (stochastic) optimal control problems with jump-diffusion processes embedded, where they allow to compute hard bounds on the optimal value. Such bounds can either be used in branch-and-bound algorithms for global optimization or simply as a way to certify optimality of a given control policy. Moreover, the bounding problems provide insights to control policy design by yielding a piecewise polynomial subsolution of the value function as byproduct. ","category":"page"},{"location":"#Which-statistics-can-you-bound?","page":"Home","title":"Which statistics can you bound?","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"As the name suggests, moment bounding schemes are primarily used to generate bounds on moments of distributions that describe jump-diffusion processes. That said, statistics that are not directly moments, however, are closely related to them such as variances or the volume of a confidence ellipsoid can be bounded as well. Moreover, by carefully choosing the distribution of which the moments are bounded, we can also bound quantities that do not directly stand out to be related to moments. The list below summarizes all quantities that can be bounded using MarkovBounds.jl.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Let x(t) in mathbbR^n be the state of the jump-diffusion process under investigation at time t  0. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"Stationary mean of polynomial observables v: ","category":"page"},{"location":"","page":"Home","title":"Home","text":"    lim_t to infty mathbbEleftv(x(t))right","category":"page"},{"location":"","page":"Home","title":"Home","text":"Note that this includes for example the mean of state x_k or more generally any moment corresponding to the multi-index i in mathbbN_0^n as special cases by choosing v(z) = z_k or v(z) = prod_k=1^n z_k^i_k, respectively. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"Stationary variance of polynomial observables v: ","category":"page"},{"location":"","page":"Home","title":"Home","text":"    lim_t to infty mathbbEleftv(x(t))^2right - mathbbEleftv(x(t))right^2","category":"page"},{"location":"","page":"Home","title":"Home","text":"Volume of stationary confidence ellipsoid of vector-valued polynomial observables mathbfv: ","category":"page"},{"location":"","page":"Home","title":"Home","text":"    lim_t to infty textdetleft(mathbbEleftmathbfv(x(t)) mathbfv(x(t))^top right - mathbbEleftmathbfv(x(t))rightmathbbEleftmathbfv(x(t))right^topright)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Probability of observing the stationary process in basic semialgebraic set X: ","category":"page"},{"location":"","page":"Home","title":"Home","text":"    lim_t to infty mathbbPleft x(t) in X right ","category":"page"},{"location":"","page":"Home","title":"Home","text":"Transient mean of polynomial observables v:","category":"page"},{"location":"","page":"Home","title":"Home","text":"    mathbbEleft v(x(t)) right","category":"page"},{"location":"","page":"Home","title":"Home","text":"Transient variance of polynomial observables v: ","category":"page"},{"location":"","page":"Home","title":"Home","text":"    mathbbEleftv(x(t))^2right - mathbbEleftv(x(t))right^2","category":"page"},{"location":"","page":"Home","title":"Home","text":"Volume of stationary confidence ellipsoid of vector-valued polynomial observables mathbfv: ","category":"page"},{"location":"","page":"Home","title":"Home","text":"    textdetleft(mathbbEleftmathbfv(x(t))mathbfv(x(t))^top right - mathbbEleftmathbfv(x(t))rightmathbbEleftmathbfv(x(t))right^topright)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Exit probability from basic semialgebraic set X subset mathbbR^n: ","category":"page"},{"location":"","page":"Home","title":"Home","text":"    mathbbPleft t_exit  t right text where  t_exit = inf_0 leq s leq t  s  x(s) notin X ","category":"page"},{"location":"","page":"Home","title":"Home","text":"Probability of observing the process in basic semialgebraic set X subset mathbbR^n: ","category":"page"},{"location":"","page":"Home","title":"Home","text":"    mathbbPleft x(t) in X right","category":"page"},{"location":"","page":"Home","title":"Home","text":"Expected time average of polynomial observable v: ","category":"page"},{"location":"","page":"Home","title":"Home","text":"mathbbEleft int_0^t v(x(s))  ds right","category":"page"},{"location":"#How-to-install-MarkovBounds.jl?","page":"Home","title":"How to install MarkovBounds.jl?","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you want to give MarkovBounds.jl a try, you can install it via Julia's package manager","category":"page"},{"location":"","page":"Home","title":"Home","text":" ]add https://github.com/FHoltorf/MarkovBounds.jl","category":"page"},{"location":"","page":"Home","title":"Home","text":"Moreover, most functionalities of MarkovBounds.jl rely on a semidefinite programming (SDP) solver that is supported by JuMP/MathOptInterface. So please make sure that the SDP solver that you are planning on using is featured on this list. While you can choose any SDP solver from this list, we recommend to use either Mosek or SeDuMi as they have shown the best results in our tests, both in terms of robustness and speed.","category":"page"},{"location":"tutorials/jump_diffusion_process/#Analysis-of-Cox-Ingersoll-Ross-Model-Modified-by-Jumps","page":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","title":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","text":"","category":"section"},{"location":"tutorials/jump_diffusion_process/","page":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","title":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","text":"Beyond jump processes modeling stochastic chemical systems, a much wider range of stochastic processes admits computable bounds on stationary and transient moments and related statistics via moment bounding schemes. Generally all jump-diffusion processes of the form","category":"page"},{"location":"tutorials/jump_diffusion_process/","page":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","title":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","text":"    dx = f(x)  dt + g(x)  dW_t + sum_i=1^n h_i(x)  dN_a_i(x)t","category":"page"},{"location":"tutorials/jump_diffusion_process/","page":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","title":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","text":"can be analyzed as long as the data:         f - drift coefficient         gg^top - diffusion matrix         h_i - jumps         a_i - arrival rates are polynomials and the state space of the system is basic closed semialgebraic (i.e., described by finitely many polynomial inequalities) or can at least be reasonably well approximated by a basic closed semialgebraic set. In the following, we show with an example how to set the bounding problems up and compute relevant statistics.","category":"page"},{"location":"tutorials/jump_diffusion_process/","page":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","title":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","text":"Let us consider the simple Cox-Ingersoll-Ross (CIR) model for the dynamics of interest rates","category":"page"},{"location":"tutorials/jump_diffusion_process/","page":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","title":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","text":"    dx =  kappa(theta-x)  dt + sigma sqrtx  dW_t","category":"page"},{"location":"tutorials/jump_diffusion_process/","page":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","title":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","text":"As can be seen from the model this is a pure diffusion process. Such a process is defined as follows:","category":"page"},{"location":"tutorials/jump_diffusion_process/","page":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","title":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","text":"using MarkovBounds, Plots, MosekTools\nκ, θ, σ = 0.15, 0.03, 0.05 # model parameters\n@polyvar(x) # states (interest rate)\nf = κ*(θ-x) # drift coefficient\ng = σ^2*x   # diffusion matrix (outer product )\nX = @set(x >= 0) # support/state space\n\ncir = DiffusionProcess(x, f, g, X)","category":"page"},{"location":"tutorials/jump_diffusion_process/","page":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","title":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","text":"With the diffusion process defined, we can bound interesting quantities such as the long term average or variance of the interest rate x simply by calling","category":"page"},{"location":"tutorials/jump_diffusion_process/","page":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","title":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","text":"mean = stationary_mean(cir, x, 2, Mosek.Optimizer)\nvar = stationary_variance(cir, x, 2, Mosek.Optimizer)","category":"page"},{"location":"tutorials/jump_diffusion_process/","page":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","title":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","text":"The numerical results certify that the mean lies between 0.029999998 and 0.030000002 while the variance is upper bounded by 2.50006 × 10^-4. These results are of course in line with the analytical mean and variance of 0.03 and 2.5 × 10^-4.","category":"page"},{"location":"tutorials/jump_diffusion_process/","page":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","title":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","text":"Similarly, bounds along a trajectory can be evaluated with ease. In order to showcase how also jump-diffusion are dealt with, let us assume that the interest rate drops to half of its value at random times characterized by a Poisson process with rate a(x) = 0.035 x. To define this process, we can simply define the jump component separately as a jump process:","category":"page"},{"location":"tutorials/jump_diffusion_process/","page":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","title":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","text":"a = 10*x # arrival rate\nh = x/2 # jump (interest rate jumps to half its value)\njumps = JumpProcess(x, a, h, X)","category":"page"},{"location":"tutorials/jump_diffusion_process/","page":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","title":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","text":"The overall jump-diffusion process is then defined in terms of the jump and diffusion process:","category":"page"},{"location":"tutorials/jump_diffusion_process/","page":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","title":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","text":"jumping_cir = JumpDiffusionProcess(jumps, cir)","category":"page"},{"location":"tutorials/jump_diffusion_process/","page":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","title":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","text":"Alternatively the process could also be defined in terms of the whole set of problem data:","category":"page"},{"location":"tutorials/jump_diffusion_process/","page":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","title":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","text":"cir_jump = JumpDiffusionProcess(x, a, h, f, g, X)","category":"page"},{"location":"tutorials/jump_diffusion_process/","page":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","title":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","text":"Now we can for example study the evolution of means and variances of this process over time:","category":"page"},{"location":"tutorials/jump_diffusion_process/","page":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","title":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","text":"Ts = [0.1, 0.25, 0.5, 1.0, 2, 3, 4, 5, 6, 7, 8, 9, 10] # time points to probe mean and variance at\nx0 = 0.01 # initial condition (deterministic - assumed)\norder = 4 # relaxation order used\nnT = 10 # number of time intervals used to discretize the time domain\nμ0 = Dict(x^i => x0^i for i in 0:order+1) # moments of the initial distribution\nvar_bounds, mean_bounds = [], []\nfor T in Ts\n    trange = range(0, T, length = nT + 1)\n    mean = transient_mean(jumping_cir, μ0, x, order, trange, Mosek.Optimizer)\n    push!(mean_bounds, mean)\n    var = transient_variance(jumping_cir, μ0, x, order, trange, Mosek.Optimizer)\n    push!(var_bounds, var)\nend","category":"page"},{"location":"tutorials/jump_diffusion_process/","page":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","title":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","text":"(Image: )","category":"page"},{"location":"tutorials/jump_diffusion_process/","page":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","title":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","text":"In case we care more about long term predictions of the interest rate, we may wanna study the stationary mean and variance of the interest rate","category":"page"},{"location":"tutorials/jump_diffusion_process/","page":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","title":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","text":"mean = stationary_mean(jumping_cir, x, 4, Mosek.Optimizer)\nvar = stationary_variance(jumping_cir, x, 4, Mosek.Optimizer)","category":"page"},{"location":"tutorials/jump_diffusion_process/","page":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","title":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","text":"The numerical results certify that the mean lies between 0.0171291 and 0.0171799 while the variance is upper bounded by 9.2741 × 10^-5.","category":"page"},{"location":"tutorials/jump_diffusion_process/","page":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","title":"Analysis of Cox-Ingersoll-Ross Model Modified by Jumps","text":"For more details on the code used in this example, please review this jupyter notebook.","category":"page"},{"location":"tutorials/optimal_control/#Optimal-Population-Control-of-Noisy-Lotka-Volterra-System","page":"Optimal Population Control of Noisy Lotka-Volterra System","title":"Optimal Population Control of Noisy Lotka-Volterra System","text":"","category":"section"},{"location":"tutorials/optimal_control/","page":"Optimal Population Control of Noisy Lotka-Volterra System","title":"Optimal Population Control of Noisy Lotka-Volterra System","text":"The same techniques used for studying the statistics of stochastic processes can be used to study different variations of stochastic optimal control problems.","category":"page"},{"location":"tutorials/optimal_control/","page":"Optimal Population Control of Noisy Lotka-Volterra System","title":"Optimal Population Control of Noisy Lotka-Volterra System","text":"In this example, we consider a problem from population control. The control system is modeling the interaction between a predator and prey species modeled by the following diffusion dynamics","category":"page"},{"location":"tutorials/optimal_control/","page":"Optimal Population Control of Noisy Lotka-Volterra System","title":"Optimal Population Control of Noisy Lotka-Volterra System","text":"        beginbmatrix dx_1  d x_2 endbmatrix = beginbmatrix γ_1 x_1 - γ_2 x_1 x_2  gamma_4 x_1 x_2 - gamma_3 x_2 - x_2 u endbmatrix  dt + beginbmatrix gamma_5 x_1   0 endbmatrix dW_t","category":"page"},{"location":"tutorials/optimal_control/","page":"Optimal Population Control of Noisy Lotka-Volterra System","title":"Optimal Population Control of Noisy Lotka-Volterra System","text":"The control action u models the hunting effort of the predator species, while x₁ and x₂ refer to the population sizes of both species. The goal is to control the population sizes to a desired level of x_1 = 075 and x_2 = 05. To that end, we solve the following optimal control problem:","category":"page"},{"location":"tutorials/optimal_control/","page":"Optimal Population Control of Noisy Lotka-Volterra System","title":"Optimal Population Control of Noisy Lotka-Volterra System","text":"beginaligned\n        min_u(cdot) quad  mathbbEleft int_0^T (x_1(t) - 075)^2 + frac(x_2(t) - 05)^210 + frac(u(t) - 05)^210 dtright \n        textst quad  u(t)  01 \n                 x(t)  mathbbR^2_+ \n                 x(0) sim mu_0\nendaligned","category":"page"},{"location":"tutorials/optimal_control/","page":"Optimal Population Control of Noisy Lotka-Volterra System","title":"Optimal Population Control of Noisy Lotka-Volterra System","text":"To solve this problem we define the associated ControlProcess in two steps. First, we define the diffusion process via its diffusion matrix, drift coeff. and state space:","category":"page"},{"location":"tutorials/optimal_control/","page":"Optimal Population Control of Noisy Lotka-Volterra System","title":"Optimal Population Control of Noisy Lotka-Volterra System","text":"@polyvar(x[1:2]) # state variables\n@polyvar(u) # control variables\n@polyvar(t) # time variable\nX = @set(x[1] >= 0 && x[2] >= 0) # state space\n\nγ = [1, 2, 1, 2, 0.25*0.1] # model parameters\n\nf = [γ[1] * x[1] - γ[2] * x[1] * x[2] ;\n     γ[4] * x[1] * x[2] - γ[3] * x[2] - x[2]*u] # drift coefficient\n\ng = [γ[5]*x[1]; 0] # diffusion coefficient\nσ = polynomial.(g*g') # diffusion matrix\n\nlv = DiffusionProcess(x, f, σ, X, time = t, controls = [u])","category":"page"},{"location":"tutorials/optimal_control/","page":"Optimal Population Control of Noisy Lotka-Volterra System","title":"Optimal Population Control of Noisy Lotka-Volterra System","text":"In a second step, we define the control process with its objective function and set of admissible control actions.","category":"page"},{"location":"tutorials/optimal_control/","page":"Optimal Population Control of Noisy Lotka-Volterra System","title":"Optimal Population Control of Noisy Lotka-Volterra System","text":"U = @set(u >= 0 && u <= 1) # set of admissible controls|\nstagecost = (x[1]-0.75)^2 + (x[2] - 0.5)^2/10 + (u - 0.5)^2/10\nobj = Lagrange(stagecost) # Lagrange type objective\nT = 10.0 # control horizon\nlv_control = ControlProcess(lv, T, U, obj)","category":"page"},{"location":"tutorials/optimal_control/","page":"Optimal Population Control of Noisy Lotka-Volterra System","title":"Optimal Population Control of Noisy Lotka-Volterra System","text":"Now almost everything is set up to determine a lower bound on the objective value associated with the control problem CP. We only need to specify the distribution of the initial state of the process. This specification is done through the moments of the distribution. In this example, we consider the the initial condition to be known deterministically such that the moments are easily computed. The moments are supplied in form of a dictionary mapping the monomial of the state to the corresponding moment.","category":"page"},{"location":"tutorials/optimal_control/","page":"Optimal Population Control of Noisy Lotka-Volterra System","title":"Optimal Population Control of Noisy Lotka-Volterra System","text":"The number of moments that needs to be specified depends on the relaxation order used: If order d is used, all moments up to order d + max(deg(f) - 1, deg(σ) - 2, 0) require specification.","category":"page"},{"location":"tutorials/optimal_control/","page":"Optimal Population Control of Noisy Lotka-Volterra System","title":"Optimal Population Control of Noisy Lotka-Volterra System","text":"order = 6\nx0 = [1.0, 0.25]\nμ0 = Dict(x[1]^i*x[2]^j => x0[1]^i*x0[2]^j for i in 0:order+1, j in 0:order+1) # moments of initial distribution\ntrange = range(0, T, length = 11) # discretization of time horizon\nb = optimal_control(lv_control, μ0, order, trange, Mosek.Optimizer)","category":"page"},{"location":"tutorials/optimal_control/","page":"Optimal Population Control of Noisy Lotka-Volterra System","title":"Optimal Population Control of Noisy Lotka-Volterra System","text":"The numerical result of this operation provides a lower bound of 0.2089 on the minimal control cost attainable by any admissible control policy.","category":"page"},{"location":"tutorials/optimal_control/","page":"Optimal Population Control of Noisy Lotka-Volterra System","title":"Optimal Population Control of Noisy Lotka-Volterra System","text":"From the optimal solution of the bounding problem, we can further identify a polynomial approximation to the value function. If the time horizon is discretized in more than one piece, this approximation will be a piecewise polynomial. By calling the value_function function as shown below we can extract this piecewise polynomial in the form of two functions. The first output maps any point (x,t) -> to the corresponding polynomial, while the second output is a function that directly evaluates this polynomial at (x,t):","category":"page"},{"location":"tutorials/optimal_control/","page":"Optimal Population Control of Noisy Lotka-Volterra System","title":"Optimal Population Control of Noisy Lotka-Volterra System","text":"V_poly, V_val = value_function(lv_control, trange, b);","category":"page"},{"location":"tutorials/optimal_control/","page":"Optimal Population Control of Noisy Lotka-Volterra System","title":"Optimal Population Control of Noisy Lotka-Volterra System","text":"This information can be used to construct controllers as shown in the following","category":"page"},{"location":"tutorials/optimal_control/","page":"Optimal Population Control of Noisy Lotka-Volterra System","title":"Optimal Population Control of Noisy Lotka-Volterra System","text":"urange = 0:0.05:1\nfunction controller(x,s)\n    obj = stagecost + extended_inf_generator(DP, V_poly(s,x))\n    return urange[argmin([obj(x...,u,s) for u in urange])]\nend\n\ndrift(x,p,t) = [f[1](x...), f[2](x..., controller(x, t))]\ndiffusion(x,p,t) = [g[1](x[1]), 0]\nprob = EnsembleProblem(SDEProblem(drift, diffusion, x0, (0.0, T)))\nsol = DifferentialEquations.solve(prob, EM(), dt = 0.01, trajectories = 100)","category":"page"},{"location":"tutorials/optimal_control/","page":"Optimal Population Control of Noisy Lotka-Volterra System","title":"Optimal Population Control of Noisy Lotka-Volterra System","text":"The obtained system trajectories are shown below. They clearly demonstrate that the above constructed controller does a reasonable job at steering the system to the desired setpoint. Moreover, after estimating the control cost achieved by this controller via sampling, the computed lower bound can be used to certify (with high confidence) that the constructed controller is no more than 3% suboptimal. ","category":"page"},{"location":"tutorials/optimal_control/","page":"Optimal Population Control of Noisy Lotka-Volterra System","title":"Optimal Population Control of Noisy Lotka-Volterra System","text":"(Image: )","category":"page"},{"location":"tutorials/optimal_control/","page":"Optimal Population Control of Noisy Lotka-Volterra System","title":"Optimal Population Control of Noisy Lotka-Volterra System","text":"For more details on the code used in this example, please review this jupyter notebook.","category":"page"}]
}
