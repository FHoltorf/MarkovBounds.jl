<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · MarkovBounds.jl</title><link rel="canonical" href="https://FHoltorf.github.io/MarkovBounds.jl/"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">MarkovBounds.jl</span></div><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a><ul class="internal"><li class="toplevel"><a class="tocitem" href="#When-should-you-consider-using-moment-bounding-schemes?"><span>When should you consider using moment bounding schemes?</span></a></li><li><a class="tocitem" href="#Stationary-Distributions"><span>Stationary Distributions</span></a></li><li><a class="tocitem" href="#Error-Control"><span>Error Control</span></a></li><li><a class="tocitem" href="#Optimal-Control-Problems"><span>Optimal Control Problems</span></a></li><li class="toplevel"><a class="tocitem" href="#Background-on-Moment-Bounding-Schemes-a-name&quot;background&quot;/a"><span>Background on Moment Bounding Schemes &lt;a name=&quot;background&quot;&gt;&lt;/a&gt;</span></a></li><li><a class="tocitem" href="#Jump-Diffusion-Processes"><span>Jump-Diffusion Processes</span></a></li><li><a class="tocitem" href="#Moment-Bounding-Schemes"><span>Moment Bounding Schemes</span></a></li><li class="toplevel"><a class="tocitem" href="#Bounds-on-Stationary-Moments-of-Markov-Processes"><span>Bounds on Stationary Moments of Markov Processes</span></a></li><li class="toplevel"><a class="tocitem" href="#Bounds-on-Transient-Moments-of-Markov-Processes"><span>Bounds on Transient Moments of Markov Processes</span></a></li><li class="toplevel"><a class="tocitem" href="#Bounds-on-Stochastic-Optimal-Control-Problems"><span>Bounds on Stochastic Optimal Control Problems</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/FHoltorf/MarkovBounds.jl/blob/master/docs/src/index.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="MarkovBounds.jl"><a class="docs-heading-anchor" href="#MarkovBounds.jl">MarkovBounds.jl</a><a id="MarkovBounds.jl-1"></a><a class="docs-heading-anchor-permalink" href="#MarkovBounds.jl" title="Permalink"></a></h1><p><a href="https://github.com/FHoltorf/MarkovBounds.jl">MarkovBounds.jl</a> is a Julia package seeking to automate the setup of moment bounding schemes for the analysis of jump-diffusion processes with the goal of enabling those unfamiliar with moment problems or optimization in general to apply moment bounding schemes regardless. To that end, MarkovBounds.jl automatically translates high-level problem data framing a jump-diffusion process as specified via convenient tools such as <a href="https://github.com/SciML/Catalyst.jl">Catalyst.jl</a>, <a href="https://github.com/JuliaSymbolics/Symbolics.jl">Symbolics.jl</a>/<a href="https://github.com/SciML/ModelingToolkit.jl">ModelingToolkit.jl</a> or <a href="https://github.com/JuliaAlgebra/DynamicPolynomials.jl">DynamicPolynomials.jl</a> into <a href="https://en.wikipedia.org/wiki/Sum-of-squares_optimization">sum-of-squares (SOS) programs</a> and solve them via the existing optimization pipeline in Julia (see <a href="https://github.com/jump-dev/SumOfSquares.jl">SumOfSquares.jl</a>, <a href="https://github.com/jump-dev/JuMP.jl">JuMP</a> and <a href="https://github.com/jump-dev/MathOptInterface.jl">MathOptInterface.jl</a>). The solution of said SOS programs are returned to the user in form of theoretically guaranteed bounds on moments and other key statistics of the process under investigation.</p><p><img src="C:\\Users\\chemegrad2018\\.julia\\dev\\MarkovBounds\\docs\\src\\images\\programstructure.PNG" alt="program structure"/></p><h1 id="When-should-you-consider-using-moment-bounding-schemes?"><a class="docs-heading-anchor" href="#When-should-you-consider-using-moment-bounding-schemes?">When should you consider using moment bounding schemes?</a><a id="When-should-you-consider-using-moment-bounding-schemes?-1"></a><a class="docs-heading-anchor-permalink" href="#When-should-you-consider-using-moment-bounding-schemes?" title="Permalink"></a></h1><p>Moment bounding schemes are limited by the capabilities of large-scale semidefinite programming. Given the current state-of-the-art, moment bounding schemes are practically limited to stochastic processes of low to medium dimensionality (&lt; 10 states). Moreover, MarkovBounds.jl currently <em>only</em> supports processes in which the data can be fully characterized in terms of <em>polynomials</em> (see <a href="#background">Background</a> for details). </p><h2 id="Stationary-Distributions"><a class="docs-heading-anchor" href="#Stationary-Distributions">Stationary Distributions</a><a id="Stationary-Distributions-1"></a><a class="docs-heading-anchor-permalink" href="#Stationary-Distributions" title="Permalink"></a></h2><p>Moment bounding schemes have been found to perform remarkably well for the study of the stationary (or ergodic) statistics of stochastic processes. They have been found to provide high quality (often effectively tight) bounds on key statistics such as means, variances, Fano factors and more at a fraction of the computational time needed to provide similarly accurate sample statistics. </p><h2 id="Error-Control"><a class="docs-heading-anchor" href="#Error-Control">Error Control</a><a id="Error-Control-1"></a><a class="docs-heading-anchor-permalink" href="#Error-Control" title="Permalink"></a></h2><p>The analysis of jump-diffusion processes relies traditionally on brute force sampling of paths of the process such that a sufficiently large sample of such paths exihibits similar statistics as the generating process. However, even though this approach works remarkably well over a wide range of applications and powerful software tools supporting this approach exist (see e.g. <a href="https://github.com/SciML/DifferentialEquations.jl">DifferentialEquations.jl</a>), it may break down in certain settings. Most notably, the generation of sample paths can become prohibitively expensive when the process under investigation is highly stiff and/or volatile, rendering simulation expensive and/or convergence of sample statistics to the true statistics slow. In those cases, practitioners tend to fall back on approximation techniques such as <span>$\tau$</span>-leaping, moment closure approximations and many more, which recover tractability at the cost of introducing unverifiable assumptions and an unknown error. Moment bounding schemes can be used to quantify/bound this error by providing hard bounds on key statistics, both in the transient and stationary setting. </p><h2 id="Optimal-Control-Problems"><a class="docs-heading-anchor" href="#Optimal-Control-Problems">Optimal Control Problems</a><a id="Optimal-Control-Problems-1"></a><a class="docs-heading-anchor-permalink" href="#Optimal-Control-Problems" title="Permalink"></a></h2><p>Moment bounding schemes extend naturally to the application of (stochastic) optimal control problems with jump-diffusion processes embedded, where they allow to compute hard bounds on the optimal value. Such bounds can either be used in branch-and-bound algorithms for global optimization or simply as a way to certify optimality of a given control policy. Moreover, the bounding problems provide insights to control policy design by yielding a piecewise polynomial subsolution of the value function as byproduct. </p><h1 id="Background-on-Moment-Bounding-Schemes-a-name&quot;background&quot;/a"><a class="docs-heading-anchor" href="#Background-on-Moment-Bounding-Schemes-a-name&quot;background&quot;/a">Background on Moment Bounding Schemes &lt;a name=&quot;background&quot;&gt;&lt;/a&gt;</a><a id="Background-on-Moment-Bounding-Schemes-a-name&quot;background&quot;/a-1"></a><a class="docs-heading-anchor-permalink" href="#Background-on-Moment-Bounding-Schemes-a-name&quot;background&quot;/a" title="Permalink"></a></h1><h2 id="Jump-Diffusion-Processes"><a class="docs-heading-anchor" href="#Jump-Diffusion-Processes">Jump-Diffusion Processes</a><a id="Jump-Diffusion-Processes-1"></a><a class="docs-heading-anchor-permalink" href="#Jump-Diffusion-Processes" title="Permalink"></a></h2><p>A jump-diffusion process is dynamical system combining a deterministic evolution of the system state, called drift, with a stochastic component modeling stochastic vibrations, called diffusion, and another stochastic component modeling discrete changes, called jumps. The evolution of the process state <span>$x_t$</span> over time <span>$t$</span> through its state space <span>$X \subset \mathbb{R}^n$</span> is governed by the following stochastic differential equation $ dx<em>t = f(x</em>t) \, dt + g(x<em>t) \, dW</em>t + \sum<em>{i=1}^{n</em>R} h(x<em>t) \, dN</em>{a<em>i(x</em>t)} $ where <span>$W_t$</span> denotes a standard <span>$\mathbb{R}^m$</span>-Brownian motion and <span>$N_{a_i(x_t)}$</span> a standard Poisson counter with rate <span>$a_i(x)$</span>. The problem data is considered</p><ul><li>drift coefficient <span>$f:\mathbb{R}^n \to \mathbb{R}^n$</span></li><li>diffusion matrix <span>$gg^\top :  \mathbb{R}^n \to \mathbb{R}^{n\times n}$</span> (or diffusion coefficient g:\mathbb{R}^n \to \mathbb{R}^{n \times m} $)</li><li>arrival rates <span>$a_i : \mathbb{R}^n \to \mathbb{R}$</span>, <span>$i  = 1,\dots, n_R$</span></li><li>jumps <span>$h_i:\mathbb{R}^n \to \mathbb{R}^n$</span>, <span>$i  = 1,\dots, n_R$</span></li><li>state space X </li></ul><p>A fundamental assumption in MarkovBounds.jl (and to a large extent moment bounding schemes inherently) is that the data of the jump-diffusion process under investigation can be fully characterized in terms of polynomials, i.e., all functions listed above are polynomials (component-wise) and the state space is (or can at least be outer approximated by) a <a href="https://www.mit.edu/~parrilo/cdc03_workshop/10_positivstellensatz_2003_12_07_02_screen.pdf">basic closed semialgebraic set</a>. Throughout, we will refer to processes that satisfies this assumption as polynomial jump-diffusion processes. A wide range of problems, in particular in the realm of stochastic chemical kinetics, lend themselves to be modeled in terms of polynomial jump-diffusion processes; if this assumption, however, is not satisfied, a simple but limited workaround is to find approximations of the data in terms of polynomials and apply the moment bounding scheme in a second step.</p><h2 id="Moment-Bounding-Schemes"><a class="docs-heading-anchor" href="#Moment-Bounding-Schemes">Moment Bounding Schemes</a><a id="Moment-Bounding-Schemes-1"></a><a class="docs-heading-anchor-permalink" href="#Moment-Bounding-Schemes" title="Permalink"></a></h2><p>The core idea behind moment bounding schemes is rather simple. But to explain it, we first need to establish some notation: Let <span>$y_i(t) = \mathbb{E} \left[ \prod_{k=1}^n x_k(t)^{i_k} \right]$</span> denote the $ i $ th moment of a polynomial jump-diffusion process as defined the previous section. Similarly, let $ \mathbf{y}<em>q(t) $  be the truncated sequence of all multivariate moments of the process up to order <span>$q \in \mathbb{N}$</span>, i.e., \mathbf{y}</em>q(t) = { y<em>i(t) | |i| \leq q } $. Due to the notrious moment closure problem, \mathbf{y}</em>q(t)$ cannot in general be computed directly via simple simulation. To circumvent this issue, moment bounding schemes now seek to identify a proxy for <span>$\mathbf{y}_q(t)$</span>, say <span>$\tilde{\mathbf{y}}_q(t)$</span>, which minimizes/maximizes a certain statistic of the process under investigation, while ensuring that <span>$\tilde{\mathbf{y}}_q(t)$</span> remains in certain ways consistent with the process under investigation (we will see shortly what that means concretely). Formally, we seek to solve an optimization problem of the form $ \begin{align} \inf<em>{\tilde{\mathbf{y}}</em>q} \quad &amp;\int<em>{0}^T l^\top \tilde{\mathbf{y}}</em>q(t) \, dt + m^\top \tilde{\mathbf{y}}<em>q(T) \
\text{s.t.} \quad &amp; \tilde{\mathbf{y}}</em>q \text{ satisfies necessary consistency conditions.} \end{align} $ The key insight underpinning all moment bounding schemes now is that a suitable choice of &quot;necessary consistency conditions&quot; turns the above &quot;pseudo&quot; optimization problem into a convex optimization problem known as generalized moment problem. The practical value of this observations lies in the fact that strong convex relaxations of these generalized moment problems are easily constructed and can be readily solved with off-the-shelve semidefinite programming (SDP) solvers such as Mosek, SeDuMi or SDPT3. </p><p>But what are these &quot;necessary consistency conditions&quot;? They can be loosely classified as a) reflecting the dynamics of the underlying process and b) the support of its distribution. Conditions of type a) are affine relations that the moments of process have to satisfy. To derive these conditions, note that the (extended) infinitesimal generator $ \mathcal{A} : w(t,z) \to \lim<em>{h\to 0^+} \frac{\mathbb{E</em>z[w(t + h,x(t + h))]} - w(t,z)}{h} = \frac{ \partial w(t,z) }{\partial t } + f(z)^\top \nabla<em>z w(t,z) + \text{Tr}\left(gg^\top(z) \nabla</em>z^2 w(t,z) \right) + \sum<em>{i=1}^{n</em>R} a<em>i(z) w(t, h</em>i(z)) $ maps polynomials to polynomials under the assumption of a polynomial jump diffusion process. Thus, the moments of such a process follow linear, albeit generally underdetermined, dynamics: $ \frac{d}{dt}\mathbb{E}\left[\prod<em>{k=1}^n x</em>k^{i<em>k}(t) \right] = \mathbb{E}\left[ \mathcal{A}\prod</em>{k=1}^n x<em>k^{i</em>k}(t) \right] \iff \frac{dy<em>i}{dt}(t) = a</em>i^\top \mathbf{y}<em>q(t) $ Conditions of type b) impose positive semidefiniteness of certain moment matrices. To see that such conditions indeed have to be satisfied by the true moments of the process, consider a one-dimensional process <span>$x(t)$</span> and a vector of the monomial basis <span>$b(x) = [1, x, x^2, \dots, x^d]$</span>. Then clearly,  the moment matrix $ \mathbb{E}\left[ b(x(t)) b(x(t))^\top \right] = \begin{bmatrix} 1 &amp; y</em>1(t) &amp; y<em>2(t)&amp;\cdots &amp; y</em>d(t) \
															    y<em>1(t) &amp; y</em>2(t) &amp; y<em>3(t) &amp; \cdots &amp; y</em>{d+1}(t) \
															    y<em>2(t) &amp; y</em>3(t)  &amp; \ddots &amp; &amp; y<em>{d+2}(t) \
															    \vdots &amp; \vdots &amp; &amp;  &amp;\vdots \
															    y</em>d(t) &amp; y<em>{d+1}(t) &amp; y</em>{d+2}(t) &amp; \cdots &amp; y<em>{2d}(t)  															    \end{bmatrix} $ must be positive semidefinite as the left-hand-side is. This argument generalizes immediately to the multivariate case. The condition, $ \mathbb{E}\left[ b(x(t)) b(x(t))^\top \right] \succeq 0, $ can be viewed as reflecting non-negativity of the probability measure describing the process state at time <span>$t$</span>. With this intuition in mind, it follows further that for any polynomial <span>$p$</span> which is non-negative on the state space <span>$X$</span>, the condition $ \mathbb{E}[p(x(t))b(x(t)) b(x(t))^\top] \succeq 0 $ reflecting the support of the probability distribution on <span>$X$</span> must also hold. Further observe that conditions of this form translate directly into [Linear Matrix Inequalities](https://en.wikipedia.org/wiki/Linear</em>matrix_inequality) on the moments of the process, suggesting that the resulting problems can be tackled via SDP. </p><p>For more details and technicalities on moment bounding schemes, please consult one of the references below.</p><h1 id="Bounds-on-Stationary-Moments-of-Markov-Processes"><a class="docs-heading-anchor" href="#Bounds-on-Stationary-Moments-of-Markov-Processes">Bounds on Stationary Moments of Markov Processes</a><a id="Bounds-on-Stationary-Moments-of-Markov-Processes-1"></a><a class="docs-heading-anchor-permalink" href="#Bounds-on-Stationary-Moments-of-Markov-Processes" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="MarkovBounds.stationary_polynomial-Tuple{MarkovProcess, AbstractPolynomialLike, Int64, Any}" href="#MarkovBounds.stationary_polynomial-Tuple{MarkovProcess, AbstractPolynomialLike, Int64, Any}"><code>MarkovBounds.stationary_polynomial</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">stationary_polynomial(MP::MarkovProcess, v::APL, d::Int, solver)</code></pre><p>returns a <em>lower</em> bound on the expecation of a polynomial observables v(x) at steady state of the Markov process MP. The bound is computed based on an SOS program over a polynomial of degree at most d; the bounds can be tightened by increasing d. The program is solved with solver.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FHoltorf/MarkovBounds.jl/blob/81b769bd9a321394328f135af745bd5427740671/src/sos_programs_stationary.jl#L28-L35">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MarkovBounds.stationary_mean-Tuple{MarkovProcess, AbstractPolynomialLike, Int64, Any}" href="#MarkovBounds.stationary_mean-Tuple{MarkovProcess, AbstractPolynomialLike, Int64, Any}"><code>MarkovBounds.stationary_mean</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">stationary_mean(MP::MarkovProcess, v::APL, d::Int, solver)</code></pre><p>returns <em>lower</em> and <em>upper</em> bound on the observable v(x) at steady state of the Markov process MP. Bounds are computed based on SOS programs over a polynomial of degree at most d; the bounds can be tightened by increasing d. The program is solved with solver.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FHoltorf/MarkovBounds.jl/blob/81b769bd9a321394328f135af745bd5427740671/src/sos_programs_stationary.jl#L44-L51">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MarkovBounds.stationary_mean" href="#MarkovBounds.stationary_mean"><code>MarkovBounds.stationary_mean</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">stationary_mean(rn::ReactionSystem, S0::Dict, S, d::Int, solver,
		scales = Dict(s =&gt; 1 for s in species(rn));
		auto_scaling = false)</code></pre><p>returns <em>lower</em> and <em>upper</em> bound on the mean of species S of the reaction network rn with initial condition S0 (for all species!). The bound is based on an SOS program of order d solved via solver; the bounds can be tightened by increasing d.</p><p>For numerical stability, it is recommended to provide scales of the expected magnitude of molecular counts for the different species at steady state. If the system is <em>closed</em> it is also possible to enable auto_scaling which will find the maximum molecular counts for each species under stoichiometry constraints (via LP).</p><p>If the initial condition of the reaction network under investigation is unknown or irrelevant, simply call</p><pre><code class="language-none">stationary_mean(rn::ReactionSystem, S, d::Int, solver,
		scales = Dict(s =&gt; 1 for s in species(rn))).</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FHoltorf/MarkovBounds.jl/blob/81b769bd9a321394328f135af745bd5427740671/src/sos_programs_stationary.jl#L62-L83">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MarkovBounds.stationary_variance-Tuple{MarkovProcess, AbstractPolynomialLike, Int64, Any}" href="#MarkovBounds.stationary_variance-Tuple{MarkovProcess, AbstractPolynomialLike, Int64, Any}"><code>MarkovBounds.stationary_variance</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">stationary_variance(MP::MarkovProcess, v::APL, d::Int, solver)</code></pre><p>returns SOS program of degree d for computation of an <em>upper</em> bound on the variance of a polynomial observables v at steady state of the Markov process MP.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FHoltorf/MarkovBounds.jl/blob/81b769bd9a321394328f135af745bd5427740671/src/sos_programs_stationary.jl#L99-L105">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MarkovBounds.stationary_variance" href="#MarkovBounds.stationary_variance"><code>MarkovBounds.stationary_variance</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">stationary_variance(rn::ReactionSystem, S0, x, d::Int, solver,
		    scales = Dict(s =&gt; 1 for s in species(rn));
		    auto_scaling = false)</code></pre><p>returns <em>upper</em> bound on the variance of species S of the reaction network rn with initial condition S0 (for all species!). The bound is based on an SOS program of degree d solved via solver; the bound can be tightened by increasing d.</p><p>For numerical stability, it is recommended to provide scales of the expected magnitude of molecular counts for the different species at steady state. If the system is <em>closed</em> it is also possible to enable auto_scaling which will find the maximum molecular counts for each species under stoichiometry constraints (via LP).</p><p>If the initial condition of the reaction network under investigation is unknown or irrelevant, simply call</p><pre><code class="language-none">stationary_variance(rn::ReactionSystem, S, d::Int, solver,
		    scales = Dict(s =&gt; 1 for s in species(rn)))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FHoltorf/MarkovBounds.jl/blob/81b769bd9a321394328f135af745bd5427740671/src/sos_programs_stationary.jl#L131-L152">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MarkovBounds.stationary_covariance_ellipsoid-Tuple{MarkovProcess, Vector{var&quot;#s25&quot;} where var&quot;#s25&quot;&lt;:AbstractPolynomialLike, Int64, Any}" href="#MarkovBounds.stationary_covariance_ellipsoid-Tuple{MarkovProcess, Vector{var&quot;#s25&quot;} where var&quot;#s25&quot;&lt;:AbstractPolynomialLike, Int64, Any}"><code>MarkovBounds.stationary_covariance_ellipsoid</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">stationary_covariance_ellipsoid(MP::MarkovProcess, v::Vector{&lt;:APL}, d::Int, solver)</code></pre><p>returns an <em>upper</em> on the volume of the covariance ellipsoid of a vector of polynomial observables v(x), i.e., det(𝔼(v(x)v(x)ᵀ)), at steady state of the Markov process MP. The bounds are computed via an SOS program of degree d, hence can be tightened by increasing d. This computation requires a solver that can deal with exponential cone constraints.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FHoltorf/MarkovBounds.jl/blob/81b769bd9a321394328f135af745bd5427740671/src/sos_programs_stationary.jl#L167-L176">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MarkovBounds.stationary_covariance_ellipsoid" href="#MarkovBounds.stationary_covariance_ellipsoid"><code>MarkovBounds.stationary_covariance_ellipsoid</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">stationary_covariance_ellipsoid(rn::ReactionSystem, S0::Dict, S::AbstractVector, d::Int, solver,
				scales = Dict(s =&gt; 1 for s in species(rn));
				auto_scaling = false)</code></pre><p>returns an <em>upper</em> on the volume of the covariance ellipsoid of any subset S of the chemical species in the reaction network rn, i.e., det(𝔼(SSᵀ)), at steady state of the associated jump process. The reaction network is assumed to have the deterministic initial state S0 (all species must be included here!). The bounds are computed via an SOS program of degree d, hence can be tightened by increasing d. This computation requires a solver that can deal with exponential cone constraints.</p><p>For numerical stability, it is recommended to provide scales of the expected magnitude of molecular counts for the different species at steady state. If the system is <em>closed</em> it is also possible to enable auto_scaling which will find the maximum molecular counts for each species under stoichiometry constraints (via LP).</p><p>If the initial condition of the reaction network under investigation is unknown or irrelevant, simply call</p><pre><code class="language-none">stationary_covariance_ellipsoid(rn::ReactionSystem, S, d::Int, solver,
				scales = Dict(s =&gt; 1 for s in species(rn)))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FHoltorf/MarkovBounds.jl/blob/81b769bd9a321394328f135af745bd5427740671/src/sos_programs_stationary.jl#L212-L236">source</a></section></article><h1 id="Bounds-on-Transient-Moments-of-Markov-Processes"><a class="docs-heading-anchor" href="#Bounds-on-Transient-Moments-of-Markov-Processes">Bounds on Transient Moments of Markov Processes</a><a id="Bounds-on-Transient-Moments-of-Markov-Processes-1"></a><a class="docs-heading-anchor-permalink" href="#Bounds-on-Transient-Moments-of-Markov-Processes" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="MarkovBounds.transient_polynomial-Tuple{MarkovProcess, Dict, AbstractPolynomialLike, Int64, AbstractVector{var&quot;#s25&quot;} where var&quot;#s25&quot;&lt;:Real, Any}" href="#MarkovBounds.transient_polynomial-Tuple{MarkovProcess, Dict, AbstractPolynomialLike, Int64, AbstractVector{var&quot;#s25&quot;} where var&quot;#s25&quot;&lt;:Real, Any}"><code>MarkovBounds.transient_polynomial</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">transient_polynomial(MP::MarkovProcess, μ0::Dict, v::APL, d::Int, trange::AbstractVector{&lt;:Real}, solver)</code></pre><p>returns a <em>lower</em> bound on 𝔼[v(x(T))] where v is a polynomial and x(T) the state of the Markov process MP at time T. μ0 encodes the distribution of the initial state of the process in terms of its moments; specifically, it maps monomials to the respective moments of the initial distribution. trange is an <em>ordered</em> collection of time points used to discretize the time horizon [0,T], i.e., trange[end] = T. Populating trange and increasing d improves the computed bound.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FHoltorf/MarkovBounds.jl/blob/81b769bd9a321394328f135af745bd5427740671/src/sos_programs_transient.jl#L54-L64">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MarkovBounds.transient_mean-Tuple{MarkovProcess, Dict, AbstractPolynomialLike, Int64, AbstractVector{var&quot;#s25&quot;} where var&quot;#s25&quot;&lt;:Real, Any}" href="#MarkovBounds.transient_mean-Tuple{MarkovProcess, Dict, AbstractPolynomialLike, Int64, AbstractVector{var&quot;#s25&quot;} where var&quot;#s25&quot;&lt;:Real, Any}"><code>MarkovBounds.transient_mean</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">transient_mean(MP::MarkovProcess, μ0::Dict, x::APL, d::Int, trange::AbstractVector{&lt;:Real}, solver)</code></pre><p>returns a <em>lower</em> and <em>upper</em> bound on 𝔼[v(x(T))] where v is a polynomial and x(T) the state of the Markov process MP at time T. μ0 encodes the distribution of the initial state of the process in terms of its moments; specifically, it maps monomials to the respective moments of the initial distribution. trange is an <em>ordered</em> collection of time points used to discretize the time horizon [0,T], i.e., trange[end] = T. Populating trange and increasing d improves the computed bounds.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FHoltorf/MarkovBounds.jl/blob/81b769bd9a321394328f135af745bd5427740671/src/sos_programs_transient.jl#L81-L91">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MarkovBounds.transient_mean" href="#MarkovBounds.transient_mean"><code>MarkovBounds.transient_mean</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">transient_mean(rn::ReactionSystem, S0::Dict, S, d::Int, trange::AbstractVector{&lt;:Number}, solver,
		scales = Dict(s =&gt; 1 for s in species(rn));
		auto_scaling = false)</code></pre><p>returns a <em>lower</em> and <em>upper</em> bound on the mean of the molecular count of species S in reaction network rn at time T. S0 refers to the <em>deterministic</em> initial state of the reaction system (including all species!). trange is an <em>ordered</em> collection of time points used to discretize the time horizon [0,T], i.e., trange[end] = T. Populating trange and increasing d improves the computed bounds.</p><p>For numerical stability, it is recommended to provide scales of the expected magnitude of molecular counts for the different species at steady state. If the system is <em>closed</em> it is also possible to enable auto_scaling which will find the maximum molecular counts for each species under stoichiometry constraints (via LP).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FHoltorf/MarkovBounds.jl/blob/81b769bd9a321394328f135af745bd5427740671/src/sos_programs_transient.jl#L108-L125">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MarkovBounds.transient_variance-Tuple{MarkovProcess, Dict, AbstractPolynomialLike, Int64, AbstractVector{var&quot;#s25&quot;} where var&quot;#s25&quot;&lt;:Real, Any}" href="#MarkovBounds.transient_variance-Tuple{MarkovProcess, Dict, AbstractPolynomialLike, Int64, AbstractVector{var&quot;#s25&quot;} where var&quot;#s25&quot;&lt;:Real, Any}"><code>MarkovBounds.transient_variance</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">transient_variance(MP::MarkovProcess, μ0::Dict, v::APL, d::Int, trange::AbstractVector{&lt;:Real}, solver)</code></pre><p>returns an <em>upper</em> bound on 𝔼[v(x(T))²] - 𝔼[v(x(T))]² where v is a polynomial and x(T) the state of the Markov process MP at time T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FHoltorf/MarkovBounds.jl/blob/81b769bd9a321394328f135af745bd5427740671/src/sos_programs_transient.jl#L135-L140">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MarkovBounds.transient_variance" href="#MarkovBounds.transient_variance"><code>MarkovBounds.transient_variance</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">transient_variance(rn::ReactionSystem, S0::Dict, S, d::Int, trange::AbstractVector{&lt;:Real}, solver,
		    scales = Dict(s =&gt; 1 for s in species(rn));
			auto_scaling = false)</code></pre><p>returns an <em>upper</em> bound on the variance of species S in the reaction network rn at time T. S0 refers to the <em>deterministic</em> initial state of the reaction system (including all species!). trange is an <em>ordered</em> collection of time points used to discretize the time horizon [0,T], i.e., trange[end] = T. Populating trange and increasing d improves the computed bounds.</p><p>For numerical stability, it is recommended to provide scales of the expected magnitude of molecular counts for the different species at steady state. If the system is <em>closed</em> it is also possible to enable auto_scaling which will find the maximum molecular counts for each species under stoichiometry constraints (via LP).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FHoltorf/MarkovBounds.jl/blob/81b769bd9a321394328f135af745bd5427740671/src/sos_programs_transient.jl#L183-L200">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MarkovBounds.transient_covariance_ellipsoid-Tuple{MarkovProcess, Dict, Vector{AbstractPolynomialLike}, Int64, AbstractVector{var&quot;#s25&quot;} where var&quot;#s25&quot;&lt;:Real, Any}" href="#MarkovBounds.transient_covariance_ellipsoid-Tuple{MarkovProcess, Dict, Vector{AbstractPolynomialLike}, Int64, AbstractVector{var&quot;#s25&quot;} where var&quot;#s25&quot;&lt;:Real, Any}"><code>MarkovBounds.transient_covariance_ellipsoid</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">transient_covariance_ellipsoid(MP::MarkovProcess, μ0::Dict, v::Vector{APL}, d::Int, trange::AbstractVector{&lt;:Real}, solver)</code></pre><p>returns an <em>upper</em> bound on the volume of the covariance ellipsoid det(𝔼(v(x(T))v(x(T))ᵀ)), where v is a polynomial and x(T) the state of the Markov process MP at time T.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FHoltorf/MarkovBounds.jl/blob/81b769bd9a321394328f135af745bd5427740671/src/sos_programs_transient.jl#L209-L214">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MarkovBounds.transient_covariance_ellipsoid" href="#MarkovBounds.transient_covariance_ellipsoid"><code>MarkovBounds.transient_covariance_ellipsoid</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">transient_covariance_ellipsoid(rn::ReactionSystem, S0::Dict, S::AbstractVector, d::Int, trange::AbstractVector{&lt;:Real}, solver,
						scales = Dict(s =&gt; 1 for s in species(rn));
						auto_scaling = false)</code></pre><p>returns an <em>upper</em> bound on the volume of the covariance ellipsoid associated with any collection of chemical species in the reaction network rn at time T. S0 refers to the <em>deterministic</em> initial state of the reaction system (including all species!). trange is an <em>ordered</em> collection of time points used to discretize the time horizon [0,T], i.e., trange[end] = T. Populating trange and increasing d improves the computed bounds.</p><p>For numerical stability, it is recommended to provide scales of the expected magnitude of molecular counts for the different species at steady state. If the system is <em>closed</em> it is also possible to enable auto_scaling which will find the maximum molecular counts for each species under stoichiometry constraints (via LP).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FHoltorf/MarkovBounds.jl/blob/81b769bd9a321394328f135af745bd5427740671/src/sos_programs_transient.jl#L265-L282">source</a></section></article><h1 id="Bounds-on-Stochastic-Optimal-Control-Problems"><a class="docs-heading-anchor" href="#Bounds-on-Stochastic-Optimal-Control-Problems">Bounds on Stochastic Optimal Control Problems</a><a id="Bounds-on-Stochastic-Optimal-Control-Problems-1"></a><a class="docs-heading-anchor-permalink" href="#Bounds-on-Stochastic-Optimal-Control-Problems" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="MarkovBounds.optimal_control-Tuple{ControlProcess, Dict, Int64, AbstractVector{var&quot;#s25&quot;} where var&quot;#s25&quot;&lt;:Real, Any}" href="#MarkovBounds.optimal_control-Tuple{ControlProcess, Dict, Int64, AbstractVector{var&quot;#s25&quot;} where var&quot;#s25&quot;&lt;:Real, Any}"><code>MarkovBounds.optimal_control</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">optimal_control(CP::ControlProcess, μ0::Dict, d::Int, trange::AbstractVector{&lt;:Real}, solver)</code></pre><p>returns a <em>lower</em> bound on the objective value of the (stochastic) optimal control problem specified by CP. μ0 encodes information about the distribution of the initial state of the process; specifically, μ0 maps a given monomial to the corresponding moment of the initial distribution. trange refers to an <em>ordered</em> set of time points discretizing the control horizon. trange[end] should coincide with the end of the control horizon, i.e., trange[end] = Inf in case of an infinite horizon problem. The bound is computed via a SOS program of degree d solved with an appropriate method given by solver.</p><p>The bound can be tightened by populating trange or increasing d.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/FHoltorf/MarkovBounds.jl/blob/81b769bd9a321394328f135af745bd5427740671/src/sos_programs_control.jl#L3-L16">source</a></section></article></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Wednesday 21 July 2021 22:07">Wednesday 21 July 2021</span>. Using Julia version 1.6.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
